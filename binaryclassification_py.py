# -*- coding: utf-8 -*-
"""Binaryclassification.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pRNTGUu16q1RrHhGLXRg-SedHHmGjGll
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

import io
df=pd.read_csv(io.BytesIO(uploaded['test.csv']))

df.head()

df.tail()

df.shape

print(df.isnull().sum())

x=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.model_selection import train_test_split
x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.2,random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import roc_auc_score,mean_squared_error,accuracy_score,classification_report,roc_curve,confusion_matrix
models = {}

#logistic regression
from sklearn.linear_model import LogisticRegression
models['Logistic Regression'] = LogisticRegression()

#Decision tree
from sklearn.tree import DecisionTreeClassifier
models['Decision Tree'] = DecisionTreeClassifier()

#XGB Boost
from xgboost import XGBClassifier
models['xgboost'] = XGBClassifier()
from sklearn.metrics import accuracy_score, precision_score, recall_score

accuracy, precision, recall ={},{},{}

for key in models.keys():


  #Fit the classifier model
  models[key].fit(x_train, y_train)

  #prediction
  predictions = models[key].predict(x_val)

  #calculate accuracy,precision,recall metrics
  accuracy[key] =  accuracy_score[predictions, y_val]
  precision[key] = precison_score[predictions, y_val]
  recall[key] = recall_score[recall, y_val]
  y_predict = models[keys].predict[x_val]
  auc = roc_auc_score(y_val, Y_predict)
  print('Classification_report:',key)
  print(Classification_report(y_val,predictions))
  false_positive_rate, true_positive_rate, threshold=roc_curve(y_val,predictions)
  print('ROC_AUC_SCORE is',roc_auc_score(y_val, predictions))

#fpr, tpr, _ =  roc_curve(y_test, predictions[:,-1])
  plt.plot(false_positive_rate, true_positive_rate)
  plt.xlabel('FPR')
  plt.ylabel('TRP')
  plt.title('ROC CURVE')
  plt.show()
  sns.heatmap(confusion_matrix(y_val, predictions), fmt='',annot=true)

# Import necessary libraries
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report, roc_curve, confusion_matrix
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming your dataset is loaded into X (features) and y (labels)
# Example: X, y = some_data_loading_function()

# Split the data into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define models dictionary
models = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'XGBoost': XGBClassifier()
}

# Dictionaries to store metrics
accuracy, precision, recall, auc_scores = {}, {}, {}, {}

# Iterate over the models and train/validate them
for key in models.keys():
    models[key].fit(x_train, y_train)

    predictions = models[key].predict(x_val)

    accuracy[key] = accuracy_score(y_val, predictions)
    precision[key] = precision_score(y_val, predictions)
    recall[key] = recall_score(y_val, predictions)
    auc_scores[key] = roc_auc_score(y_val, predictions)

    print(f'Classification Report for {key}:')
    print(classification_report(y_val, predictions))

    false_positive_rate, true_positive_rate, _ = roc_curve(y_val, predictions)

    plt.plot(false_positive_rate, true_positive_rate, label=f'{key} ROC Curve')
    plt.xlabel('False Positive Rate (FPR)')
    plt.ylabel('True Positive Rate (TPR)')
    plt.title(f'ROC Curve - {key}')
    plt.legend()
    plt.show()

    sns.heatmap(confusion_matrix(y_val, predictions), annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix - {key}')
    plt.show()